{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc5745c1-d6c2-4cd9-85f9-fe5bacf34195",
   "metadata": {},
   "source": [
    "The objectives of this first lab session are the following:\n",
    "- Familiarize yourself with pytorch\n",
    "- Train a model from scratch using a state of the art architecture\n",
    "- Learn how to load your saved models\n",
    "- Explore hyperparameters of a given architecture\n",
    "\n",
    "We will perform all experiments on the CIFAR10 dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73970401-463c-4fa5-b352-f63596ce0c67",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "\n",
    "Familiarize yourself with pytorch by doing the [Pytorch_tutorial.ipynb](Pytorch_tutorial.ipynb), a jupyter notebook that you will be able to run also in VScode, after installing the Jupyter extension (remember to \"Trust\" the notebook, as explained [here](https://code.visualstudio.com/docs/python/jupyter-support)). If you are familiar with pytorch, you can go quickly over the tutorial and try to train a classifier in section 4 where you are asked to complete some cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00b5756-db73-4761-9457-e0d64d04f1b4",
   "metadata": {},
   "source": [
    "## Part 2 \n",
    "\n",
    "The following code can be used to obtain a DataLoader for CIFAR10, ready for training in pytorch : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd94dce5-79fe-490a-8f1b-008d6df8ffdf",
   "metadata": {},
   "source": [
    "see https://github.com/kuangliu/pytorch-cifar/tree/master/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0956800b-76e4-44cf-9b2f-06119423fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np \n",
    "from matplotlib.pylab import plt\n",
    "import gc\n",
    "import polars as pl\n",
    "import time\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import random_split\n",
    "from models_cifar100 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79a4229f-99ec-4900-9f1f-c4d65d93ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7fc2d0-b7ad-4229-b57e-4bb1d9274e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalization adapted for CIFAR10\n",
    "normalize_scratch = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "# Transforms is a list of transformations applied on the 'raw' dataset before the data is fed to the network. \n",
    "# Here, Data augmentation (RandomCrop and Horizontal Flip) are applied to each batch, differently at each epoch, on the training set data only\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize_scratch,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "953ec276-51da-4bbd-9f8c-e0b8d6b60c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### The data from CIFAR10 will be downloaded in the following folder\n",
    "rootdir = './data/cifar10'\n",
    "\n",
    "dataset = CIFAR10(rootdir,train=True,download=True,transform=transform_train)\n",
    "test_dataset = CIFAR10(rootdir,train=False,download=True,transform=transform_test)\n",
    "\n",
    "torch.manual_seed(43)\n",
    "val_size = int(len(dataset)*0.1)\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "547e4046-e2c0-4bf4-885b-1b99b61aba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds,batch_size=32,shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f257b686-451b-4b74-9f99-09d2e04c894c",
   "metadata": {},
   "source": [
    "However, this will load the entire CIFAR10 dataset, which has 50000 examples per class for training ; this can result in a relatively long training. As a consequence, we encourage you to use the following code, with a [RandomSampler](https://pytorch.org/docs/stable/data.html#torch.utils.data.RandomSampler) in order to use a subset of training : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "301745e0-7083-4fe3-bf74-11b5eeaa5751",
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of target samples for the final dataset\n",
    "num_train_examples = len(dataset)\n",
    "num_samples_subset = 15000\n",
    "\n",
    "## We set a seed manually so as to reproduce the results easily\n",
    "seed  = 2147483647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3502b19e-ae13-42aa-8ad3-fafce983cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate a list of shuffled indices ; with the fixed seed, the permutation will always be the same, for reproducibility\n",
    "indices = list(range(num_train_examples))\n",
    "np.random.RandomState(seed=seed).shuffle(indices)## modifies the list in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6f6de9c-59bb-443a-baaf-bf3295749436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We define the Subset using the generated indices \n",
    "c10train_subset = torch.utils.data.Subset(dataset,indices[:num_samples_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bc70337-efb7-4d7d-a3f8-ca85e074d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can define anoter dataloader for the training data\n",
    "trainloader_subset = DataLoader(c10train_subset,batch_size=32,shuffle=True)\n",
    "### You can now use either trainloader (full CIFAR10) or trainloader_subset (subset of CIFAR10) to train your networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a9a78cb-65d0-493a-8d9c-18c8f7d117ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(avg_train_losses, avg_val_losses, model_name):\n",
    "    # simple plot without tensorboard of the training and validation loss values\n",
    "    epochs = range(EPOCHS)\n",
    "    #avg_val_losses=[s.detach().cpu().numpy() for s in avg_val_losses] \n",
    "    \n",
    "    plt.plot(epochs, avg_train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, avg_val_losses, label='Validation Loss')\n",
    "     \n",
    "    # Add in a title and axes labels\n",
    "    plt.title(f'{model_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "     \n",
    "    # Set the tick locations\n",
    "     \n",
    "    # Display the plot\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20609988-4478-4724-b50b-0a9113a2f464",
   "metadata": {},
   "source": [
    "We will now define a state of the art deep model and train it from scratch. Check out [here](https://github.com/kuangliu/pytorch-cifar/tree/master/models) for reference implementations of modern deep models for CIFAR10. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21e44e-cb63-44db-83ae-d74cc92edc56",
   "metadata": {},
   "source": [
    "### TASK 1. Train a model from scratch\n",
    "\n",
    "Choose a model among the following ones : \n",
    "- ResNet\n",
    "- PreActResNet\n",
    "- DenseNet\n",
    "- VGG\n",
    "  \n",
    "Next, train it on a subset of CIFAR10. Try to compare with the performances on the full CIFAR10 [reported here](https://github.com/kuangliu/pytorch-cifar). \n",
    "\n",
    "A few hints : \n",
    "- Learning rate is a very important (if not the most important) hyperparameter, and is routinely scheduled to change a few times during training. A typical strategy is to divide it by 10 when reaching a plateau in performance. \n",
    "- Be careful with overfitting, which happens when the gap between Train and Test accuracy keeps getting larger. \n",
    "- Think about plotting and saving your results, so as not to lose track of your experiments. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c170369e-4a69-495a-b001-f7fb63705f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use CE loss for multi-class classification\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21607c66-4947-45a1-85b1-4310cdab7fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4ef258f-8b9a-4874-a2df-b84914ddceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c22036e-529d-4d97-ac3e-26ca1f7a8aaf",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f3b9774-1537-4950-bf55-ec8a8cfc1f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "    model.train(True)\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    last_loss = running_loss / len(train_loader) # loss per batch\n",
    "    #print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "    tb_x = epoch_index * len(train_loader) + i + 1\n",
    "    tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fc485ac-ab5e-4c39-8507-509263bebfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model, val_loader, criterion):\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = criterion(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "    return running_vloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e33b866-9208-4589-a698-3474970c7c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, epoch, best_acc):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            #print(f'Test  batch loss: {test_loss/(batch_idx+1)}, acc: {100.*correct/total}')\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27cfc20-4f93-4363-a1f5-ee49f0269577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, optimizer, save_models=False, use_scheduler=False):\n",
    "    print(model_name)\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "    avg_train_losses=[]\n",
    "    avg_val_losses = []\n",
    "    epoch_number = 0\n",
    "    best_vloss = 1_000_000.\n",
    "    best_test_acc = 0  \n",
    "\n",
    "    writer = SummaryWriter(f'runs/lab1_{model_name}_{learning_rate}_{timestamp}_{epoch_number}')\n",
    "    \n",
    "    if use_scheduler:\n",
    "        # Create a ReduceLROnPlateau scheduler - updates learning rate of the optimizer\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "        \n",
    "    for epoch in range(EPOCHS):\n",
    "        avg_loss = train_one_epoch(model, optimizer, epoch_number, writer)\n",
    "        running_vloss = 0.0\n",
    "\n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        running_vloss = validate_epoch(model, val_loader, criterion)\n",
    "        if use_scheduler:\n",
    "            scheduler.step(running_vloss)\n",
    "            # Check if the learning rate was reduced\n",
    "            #if scheduler.optimizer.param_groups[0]['lr'] < 0.1:\n",
    "            #    print(\"Learning rate reduced to:\", scheduler.optimizer.param_groups[0]['lr'])\n",
    "    \n",
    "        avg_vloss = (running_vloss / (len(val_loader))).item()\n",
    "        print(f'Epoch: {epoch_number + 1}, Loss train: {avg_loss}, valid: {avg_vloss}')\n",
    "        avg_train_losses.append(avg_loss)\n",
    "        avg_val_losses.append(avg_vloss)\n",
    "    \n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        writer.add_scalars('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch_number + 1)\n",
    "        writer.flush()\n",
    "    \n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            if save_models:\n",
    "                # see https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "                state = {\n",
    "                        'net': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'epoch': epoch_number,\n",
    "                        'learning_rate': learning_rate\n",
    "                }   \n",
    "                model_path = f'models/lab1_{model_name}_{learning_rate}_{timestamp}_{epoch_number}'\n",
    "                torch.save(state, model_path)\n",
    "    \n",
    "        epoch_number += 1\n",
    "        best_test_acc = test_epoch(model, epoch, best_test_acc)\n",
    "    torch.cuda.empty_cache() \n",
    "    gc.collect()\n",
    "    return avg_train_losses, avg_val_losses, best_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "027d8e18-0281-41fd-a08c-b1910516c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SGD optimizer with momentum\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9  # The momentum parameter (typically between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f228a65-0033-41fb-8289-1166e33ab614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def workflow(model, model_name):\n",
    "    global learning_rate \n",
    "    for lr in [0.1, 0.01, 0.001]:\n",
    "        start_time = time.time()\n",
    "        learning_rate=lr\n",
    "        model = model.to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        avg_train_losses, avg_val_losses, best_test_acc = train_model(model, model_name, optimizer, save_models=True, use_scheduler=False)\n",
    "        print(f'{model_name}, lr: {lr}, train loss: {avg_train_losses}, val loss: {avg_val_losses}, test accuracy: {best_test_acc}, elapsed: {time.time()-start_time}')\n",
    "    return avg_train_losses, avg_val_losses, best_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "134f7403-263d-430a-9098-c30e432c9f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models():\n",
    "    results={}\n",
    "\n",
    "    model = VGG('VGG11')\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model, model_name='VGG11')\n",
    "    results['VGG11']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = VGG('VGG16')\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model, model_name='VGG16')\n",
    "    results['VGG16']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = VGG('VGG19')\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model, model_name='VGG19')\n",
    "    results['VGG19']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    '''\n",
    "    model = DenseNet201()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc =workflow(model)\n",
    "    results['DenseNet201']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    \n",
    "    model = DenseNet121()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['DenseNet121']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = PreActResNet152()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['PreActResNet152']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = PreActResNet50()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['PreActResNet50']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = PreActResNet18()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['PreActResNet18']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = ResNet152()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['ResNet152']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = ResNet50()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['ResNet50']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "\n",
    "    model = ResNet18()\n",
    "    avg_train_losses, avg_val_losses, best_test_acc=workflow(model)\n",
    "    results['ResNet18']=[avg_train_losses, avg_val_losses, best_test_acc]\n",
    "    '''\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eae3bb7e-4f59-4cb9-b8f2-08671e5308d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG11\n",
      "Epoch: 1, Loss train: 2.4082599359788874, valid: 1.9863086938858032\n",
      "Epoch: 2, Loss train: 1.875736608688257, valid: 1.680523157119751\n",
      "Epoch: 3, Loss train: 1.6260565939996796, valid: 1.5131245851516724\n",
      "Epoch: 4, Loss train: 1.4205464383940707, valid: 1.2960678339004517\n",
      "Epoch: 5, Loss train: 1.2194157620652313, valid: 1.154921293258667\n",
      "VGG11, lr: 0.1, train loss: [2.4082599359788874, 1.875736608688257, 1.6260565939996796, 1.4205464383940707, 1.2194157620652313], val loss: [1.9863086938858032, 1.680523157119751, 1.5131245851516724, 1.2960678339004517, 1.154921293258667], test accuracy: 60.54, elapsed: 162.9731638431549\n",
      "VGG11\n",
      "Epoch: 1, Loss train: 0.9514702583935215, valid: 0.9156564474105835\n",
      "Epoch: 2, Loss train: 0.8957802075270481, valid: 0.8610573410987854\n",
      "Epoch: 3, Loss train: 0.8596057001165066, valid: 0.873680830001831\n",
      "Epoch: 4, Loss train: 0.826106903077697, valid: 0.8332135677337646\n",
      "Epoch: 5, Loss train: 0.7975791821093448, valid: 0.7951822876930237\n",
      "VGG11, lr: 0.01, train loss: [0.9514702583935215, 0.8957802075270481, 0.8596057001165066, 0.826106903077697, 0.7975791821093448], val loss: [0.9156564474105835, 0.8610573410987854, 0.873680830001831, 0.8332135677337646, 0.7951822876930237], test accuracy: 73.84, elapsed: 164.84813976287842\n",
      "VGG11\n",
      "Epoch: 1, Loss train: 0.7507261769010738, valid: 0.7591395974159241\n",
      "Epoch: 2, Loss train: 0.7375311164798344, valid: 0.7572782635688782\n",
      "Epoch: 3, Loss train: 0.7346407328206085, valid: 0.7594857811927795\n",
      "Epoch: 4, Loss train: 0.7246889933551891, valid: 0.7403478622436523\n",
      "Epoch: 5, Loss train: 0.7196885601755737, valid: 0.7376779317855835\n",
      "VGG11, lr: 0.001, train loss: [0.7507261769010738, 0.7375311164798344, 0.7346407328206085, 0.7246889933551891, 0.7196885601755737], val loss: [0.7591395974159241, 0.7572782635688782, 0.7594857811927795, 0.7403478622436523, 0.7376779317855835], test accuracy: 75.44, elapsed: 164.21219396591187\n",
      "VGG16\n",
      "Epoch: 1, Loss train: 2.4581294595220875, valid: 2.318812131881714\n",
      "Epoch: 2, Loss train: 2.324741343021732, valid: 2.3429884910583496\n",
      "Epoch: 3, Loss train: 2.1504529642567367, valid: 1.9711397886276245\n",
      "Epoch: 4, Loss train: 1.89890605732322, valid: 1.7991490364074707\n",
      "Epoch: 5, Loss train: 1.6832030432056517, valid: 1.5492851734161377\n",
      "VGG16, lr: 0.1, train loss: [2.4581294595220875, 2.324741343021732, 2.1504529642567367, 1.89890605732322, 1.6832030432056517], val loss: [2.318812131881714, 2.3429884910583496, 1.9711397886276245, 1.7991490364074707, 1.5492851734161377], test accuracy: 42.58, elapsed: 202.94343423843384\n",
      "VGG16\n",
      "Epoch: 1, Loss train: 1.3936827745349507, valid: 1.3084070682525635\n",
      "Epoch: 2, Loss train: 1.3050461128068123, valid: 1.2401108741760254\n",
      "Epoch: 3, Loss train: 1.2003835867971246, valid: 1.1238536834716797\n",
      "Epoch: 4, Loss train: 1.1169289988071764, valid: 1.0599931478500366\n",
      "Epoch: 5, Loss train: 1.038913322706636, valid: 0.9852988123893738\n",
      "VGG16, lr: 0.01, train loss: [1.3936827745349507, 1.3050461128068123, 1.2003835867971246, 1.1169289988071764, 1.038913322706636], val loss: [1.3084070682525635, 1.2401108741760254, 1.1238536834716797, 1.0599931478500366, 0.9852988123893738], test accuracy: 64.95, elapsed: 202.8826379776001\n",
      "VGG16\n",
      "Epoch: 1, Loss train: 0.9381178976503263, valid: 0.9198775887489319\n",
      "Epoch: 2, Loss train: 0.9194757138361046, valid: 0.9033486247062683\n",
      "Epoch: 3, Loss train: 0.9068182014622583, valid: 0.901345431804657\n",
      "Epoch: 4, Loss train: 0.8879329331732847, valid: 0.9055619239807129\n",
      "Epoch: 5, Loss train: 0.8817712759920783, valid: 0.8825280666351318\n",
      "VGG16, lr: 0.001, train loss: [0.9381178976503263, 0.9194757138361046, 0.9068182014622583, 0.8879329331732847, 0.8817712759920783], val loss: [0.9198775887489319, 0.9033486247062683, 0.901345431804657, 0.9055619239807129, 0.8825280666351318], test accuracy: 69.21, elapsed: 196.94685578346252\n",
      "VGG19\n",
      "Epoch: 1, Loss train: 2.4634717861302966, valid: 2.32621431350708\n",
      "Epoch: 2, Loss train: 2.3261599496653, valid: 2.3994152545928955\n",
      "Epoch: 3, Loss train: 2.321487925793147, valid: 2.3268826007843018\n",
      "Epoch: 4, Loss train: 2.3172810875784866, valid: 2.3710691928863525\n",
      "Epoch: 5, Loss train: 2.274766439652731, valid: 2.0806407928466797\n",
      "VGG19, lr: 0.1, train loss: [2.4634717861302966, 2.3261599496653, 2.321487925793147, 2.3172810875784866, 2.274766439652731], val loss: [2.32621431350708, 2.3994152545928955, 2.3268826007843018, 2.3710691928863525, 2.0806407928466797], test accuracy: 16.81, elapsed: 213.42616295814514\n",
      "VGG19\n",
      "Epoch: 1, Loss train: 1.9864602614228575, valid: 1.9447720050811768\n",
      "Epoch: 2, Loss train: 1.9396112707378006, valid: 1.9749013185501099\n",
      "Epoch: 3, Loss train: 1.916621664016062, valid: 1.921032190322876\n",
      "Epoch: 4, Loss train: 1.8830047667068883, valid: 1.9116672277450562\n",
      "Epoch: 5, Loss train: 1.7947059227544193, valid: 1.8113449811935425\n",
      "VGG19, lr: 0.01, train loss: [1.9864602614228575, 1.9396112707378006, 1.916621664016062, 1.8830047667068883, 1.7947059227544193], val loss: [1.9447720050811768, 1.9749013185501099, 1.921032190322876, 1.9116672277450562, 1.8113449811935425], test accuracy: 30.21, elapsed: 212.46531295776367\n",
      "VGG19\n",
      "Epoch: 1, Loss train: 1.7216878809993286, valid: 1.722909927368164\n",
      "Epoch: 2, Loss train: 1.709682702086204, valid: 1.7433034181594849\n",
      "Epoch: 3, Loss train: 1.6995956309738105, valid: 1.7263644933700562\n",
      "Epoch: 4, Loss train: 1.6935327996916185, valid: 1.6862688064575195\n",
      "Epoch: 5, Loss train: 1.6820957905532794, valid: 1.7286349534988403\n",
      "VGG19, lr: 0.001, train loss: [1.7216878809993286, 1.709682702086204, 1.6995956309738105, 1.6935327996916185, 1.6820957905532794], val loss: [1.722909927368164, 1.7433034181594849, 1.7263644933700562, 1.6862688064575195, 1.7286349534988403], test accuracy: 36.6, elapsed: 209.5031111240387\n"
     ]
    }
   ],
   "source": [
    "results = compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6507a-9215-48b6-a8e4-80dc8f324f53",
   "metadata": {},
   "source": [
    "### TASK 2. Figure Accuracy vs Number of Parameters\n",
    "Consider the four models of TASK 1. and, taking in account the [accuracy obtained on CIFAR10](https://github.com/kuangliu/pytorch-cifar), generate a graph accuracy vs number of parameters such as this one\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65e781a5-ca07-4d71-a379-d090f0f18289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params():\n",
    "    results={}\n",
    "\n",
    "    model = DenseNet201()\n",
    "    params=get_num_parameters(model)\n",
    "    results['DenseNet201']=params\n",
    "    \n",
    "    model = DenseNet121()\n",
    "    params=get_num_parameters(model)\n",
    "    results['DenseNet121']=params\n",
    "\n",
    "    model = PreActResNet152()\n",
    "    params=get_num_parameters(model)\n",
    "    results['PreActResNet152']=params\n",
    "\n",
    "    model = PreActResNet50()\n",
    "    params=get_num_parameters(model)\n",
    "    results['PreActResNet50']=params\n",
    "\n",
    "    model = PreActResNet18()\n",
    "    params=get_num_parameters(model)\n",
    "    results['PreActResNet18']=params\n",
    "\n",
    "    model = ResNet152()\n",
    "    params=get_num_parameters(model)\n",
    "    results['ResNet152']=params\n",
    "\n",
    "    model = ResNet50()\n",
    "    params=get_num_parameters(model)\n",
    "    results['ResNet50']=params\n",
    "\n",
    "    model = ResNet18()\n",
    "    params=get_num_parameters(model)\n",
    "    results['ResNet18']=params\n",
    "\n",
    "    model = VGG('VGG11')\n",
    "    params=get_num_parameters(model)\n",
    "    results['VGG11']=params\n",
    "\n",
    "    model = VGG('VGG19')\n",
    "    params=get_num_parameters(model)\n",
    "    results['VGG19']=params\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14b400b0-608c-4716-9465-88cf8ade4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_parameters(model):\n",
    "    # trainable parameters\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b9149d-542a-41d0-8303-1200abaf1e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = get_model_params()\n",
    "#param_polar=pl.from_dict(results)\n",
    "param_polar=pl.read_csv('models/model_parameters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53db51bf-e78e-4b0b-ba70-a31e7172bc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DenseNet201</th><th>DenseNet121</th><th>PreActResNet152</th><th>PreActResNet50</th><th>PreActResNet18</th><th>ResNet152</th><th>ResNet50</th><th>ResNet18</th><th>VGG11</th><th>VGG16</th><th>VGG19</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>18277220</td><td>7048548</td><td>58329252</td><td>23693476</td><td>11217316</td><td>58341028</td><td>23705252</td><td>11220132</td><td>9277284</td><td>14774436</td><td>20086692</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 11)\n",
       "┌────────────┬────────────┬────────────┬────────────┬───┬──────────┬─────────┬──────────┬──────────┐\n",
       "│ DenseNet20 ┆ DenseNet12 ┆ PreActResN ┆ PreActResN ┆ … ┆ ResNet18 ┆ VGG11   ┆ VGG16    ┆ VGG19    │\n",
       "│ 1          ┆ 1          ┆ et152      ┆ et50       ┆   ┆ ---      ┆ ---     ┆ ---      ┆ ---      │\n",
       "│ ---        ┆ ---        ┆ ---        ┆ ---        ┆   ┆ i64      ┆ i64     ┆ i64      ┆ i64      │\n",
       "│ i64        ┆ i64        ┆ i64        ┆ i64        ┆   ┆          ┆         ┆          ┆          │\n",
       "╞════════════╪════════════╪════════════╪════════════╪═══╪══════════╪═════════╪══════════╪══════════╡\n",
       "│ 18277220   ┆ 7048548    ┆ 58329252   ┆ 23693476   ┆ … ┆ 11220132 ┆ 9277284 ┆ 14774436 ┆ 20086692 │\n",
       "└────────────┴────────────┴────────────┴────────────┴───┴──────────┴─────────┴──────────┴──────────┘"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_polar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37bc4a54-036c-46f5-97d0-d960067ea882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_acc={'VGG16':92.64,'ResNet18':93.02, 'ResNet50':93.62,'DenseNet121':95.04,'PreActResNet18':95.11}\n",
    "model_params={'VGG16':14774436,'ResNet18':11220132, 'ResNet50':23705252,'DenseNet121':7048548,'PreActResNet18':11217316}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9c0ad72-aafb-492d-abb5-5d755552acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_vs_params(model_acc, model_params):\n",
    "    x_range = list(model_params.values())\n",
    "    y_vals = list(model_acc.values())\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x_range, y_vals)\n",
    "    for i, text in enumerate(model_acc.keys()):\n",
    "        ax.annotate(text, (x_range[i], y_vals[i]))\n",
    "    plt.xlabel('Parameters')\n",
    "    plt.ylabel('Accuacy')\n",
    "     \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14ac404d-774d-4e68-8d13-e659dd131c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_vs_params(model_acc, model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf17a294-8c78-4a4b-876e-37a2ab869888",
   "metadata": {},
   "outputs": [],
   "source": [
    "![Image](accuracy_vs_parameters_imagenet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde0edd-8b1c-4666-a812-d58b9da14377",
   "metadata": {},
   "source": [
    "## Part 3: Save and reload your trained models\n",
    "\n",
    "\n",
    "Pytorch has a [page](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) explaining how to save and load models. But here are a few additional details. \n",
    "\n",
    "You explored various architecture hyperparameters and saved your trained models. In order to load a model, you need to define the model in the same way that it was defined when training it. \n",
    "\n",
    "Let's assume your model definition during training had a single hyperparameter that you explored with various values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be0657-ff04-4c40-af8b-9eb91c090d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySuperModel(hyperparam = hparam_currentvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f4d10-55f8-44de-b9bc-cf044c602de2",
   "metadata": {},
   "source": [
    "The following code enables you to save the currently trained model (his parameters, it is called a *state dictionary* in pytorch) as well as the current value `hparam_currentvalue` of the hyperparameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671ab02-4ea8-47ad-a9f9-d4890d5bca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "        'net': model.state_dict(),\n",
    "        'hyperparam': hparam_currentvalue\n",
    "}\n",
    "\n",
    "torch.save(state, 'mybestmodel.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789855f4-7d89-42a4-a0ff-3c63f9a92d1e",
   "metadata": {},
   "source": [
    "In order to reload this model, first we need to define it. This means we need to fetch the value of the hyperparameter before defining the model and loading the trained parameters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4a4145-0b39-4c63-9810-ff78b8cef969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the dictionary\n",
    "loaded_cpt = torch.load('mybestmodel.pth')\n",
    "\n",
    "# Fetch the hyperparam value\n",
    "hparam_bestvalue = loaded_cpt['hyperparam']\n",
    "\n",
    "# Define the model \n",
    "model = MySuperModel(hyperparam = hparam_bestvalue)\n",
    "\n",
    "# Finally we can load the state_dict in order to load the trained parameters \n",
    "model.load_state_dict(loaded_cpt['net'])\n",
    "\n",
    "# If you use this model for inference (= no further training), you need to set it into eval mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f65915-3640-4782-b142-2a629484c219",
   "metadata": {},
   "source": [
    "## Part 4 - Project\n",
    "\n",
    "Prepare a presentation (10 minutes + 5 minutes question) with the following content : \n",
    "- Description of the chosen architecture\n",
    "- Hyperparameter exploration strategy \n",
    "- Results on CIFAR10 subset, focusing on illustrating the **compromises between model size, training time and performance**\n",
    "\n",
    "If you are ahead in time, you can perform similar experiments on the full CIFAR-10 and CIFAR-100, but be aware that each run (e.g. 350 epochs) might take as long as 3 hours.\n",
    "\n",
    "**N.B. It is very important that you consider the models in the kuangliu repository, as they have been dimensioned for the CIFAR-10 dataset. Respective models taken from other sources may be have been optimized for other datasets and therefore not adapted (over or underparametrized) to CIFAR-10.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23115502-8be2-4cc2-a00d-e500012a8a9e",
   "metadata": {},
   "source": [
    "Conducted simple experiment using 3 VGG models, and varying the learning rate hyperparmater by three orders of magnitude on each of the VGG models. \n",
    "- Disabled learning rate update scheduler.\n",
    "- Trained for 5 ephochs using full CIFAR10 dataset, note I am using a validation set - not specified in lab but is best practice.\n",
    "- Saved each model where there was an improvement over previous model (for same architecture).\n",
    "- Used tensorboard for train/validation loss monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4516a8d5-8885-4119-82b1-97fd82e3bee8",
   "metadata": {},
   "source": [
    "As discussed in the lab notes above the \"learning rate is a very important (if not the most important) hyperparameter\" - and has a very large effect. VGG11 has best test accuracy, learning rate of 0.01 was best. Undertrained - more epochs for all models and learning rates  would improve accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddfc342-bc70-42b8-886b-0c3cd85604ea",
   "metadata": {},
   "source": [
    "![Image](images/lab1_loss_lr.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e27510-71ec-47fb-8566-f4de1c72336b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
